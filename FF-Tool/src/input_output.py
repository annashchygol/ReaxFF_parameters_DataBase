#!/usr/bin/python
import os
import argparse
import logging
import yaml
import glob
import re
import numpy as np
#1. Check if path exists;
#2. If not - create a folder;
#3. Go to the folder;
#4. Check if the file with a given name exists;
#5. If yes - delete it;
#6. Create a file there with a given name;
#7. Make it based on argparse,


def natural_sort(l): 
    convert = lambda text: int(text) if text.isdigit() else text.lower() 
    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] 
    return sorted(l, key = alphanum_key)

def goToPath(path):
    if not os.path.exists(path):
        os.makedirs(path)
    os.chdir(path)


def getFweights(lst):
    print('lst:', lst)
    # Condition that ffs are generated by MCFF Optimization:[format: ff.<#iter>] 
    if (lst[0].split('.')[0] == 'ff'): 

        l = [int(s.split('.')[1]) for s in lst]
        l2 = l[1:]
        #print('l2', l2, '\n l', l)
        l2.append(1) # Sure? Maybe I should always set it to 1; // Logical to set it to other value;
        # Doesn't really matter; in the final array I'll set it to 1; 
        ll = np.array(l2) - np.array(l)
        ll[-1] = 1
        print ('Fweights are:', ll)
        np.savetxt('Fweights.out', ll, fmt = '%5i')


def getFiles(path): #returns list with absolute paths to files; #Name can be always split further; Only in case it's a path to dir;
    ls = os.listdir(path)

    # Added filtering files by the name [should contain ff]; not realluy necessary.
    print ('getFiles ls:', ls)
    filteredLs = list(filter(lambda x: x.lower().startswith('ff') or x.lower().endswith('ff'), ls))
    print ('Filtered ls:', filteredLs)
    # Sorting list in the natural order;
    sortedLs = natural_sort(filteredLs) 
    print ('Naturally sorted:', sortedLs)

    getFweights(sortedLs) # this should be called only if ff name follows certain pattern:
    ls = [os.path.join(path, file) for file in sortedLs]
    return ls


def makeUpdateFile(path, fileName, inputStr = None):
    filePath = os.path.join(path, fileName)
    logging.info("FilePath " + filePath)

    if os.path.exists(filePath):
        os.remove(filePath)

    file = open(fileName, 'a')
    if inputStr:
        file.write(inputStr)
    file.close()
    return file


def makePath(path):
    os.makedirs(path)
    logging.debug("created path: " + path)
    return path


def checkPathExistance(path, logstr):
    if os.path.exists(path): # It's not Relative path as well;
        logging.debug(logstr + path)
        return True
    else:
        return False


def handleRelativeAbsolutePath(path, createPath = False, createDBPath = False):
    logging.info("Handling: " + path)
    absPath = os.path.abspath(path)
    logging.debug("Potential absPath: " + absPath)

    if checkPathExistance(absPath, "Absolute path exists: "):
        return absPath

    else:
        DBdir = os.path.dirname(os.getcwd())
        logging.info("DBdir name:" + DBdir)
        pathFromDB = ''.join([DBdir, path])
        logging.debug("Potential DBPath: " + pathFromDB)
        pathfromFFTool = ''.join([DBdir, '/FF-Tool', path])
        print("FF-Tool path: ", pathfromFFTool)

        logging.debug("Potential FFTPath: " + pathfromFFTool)
        if checkPathExistance(pathfromFFTool, "Path from FF-Tool dir exists: "):
            return pathfromFFTool

        elif checkPathExistance(pathFromDB, "Path from DB exists: "):
            return pathFromDB

        if createPath:
            return makepath(absPath)

        elif createDBPath:
            return makepath(pathFromDB)

        #except Exception as e:
        logging.error('Non-existant path!') #('Non-existant path! %s' %(e))
        raise RuntimeError('Non-existant path: ' + path)


def fileOrFolder(path):
    files = []
    logging.debug("Path: " + '{}'.format(path))
    # Zachem peredavat' path, chtoby potom obratitsya k option,files
    for path1 in path:
        path1 = handleRelativeAbsolutePath(path1)

        if os.path.isfile(path1):
            logging.debug ('File')
            files.append(path1)

        if os.path.isdir(path1):
            logging.debug ('Dir')
            files.extend(os.listdir(path1))

    print(files)
    logging.info("List of files" + '{}'.format(files))
    logging.info('{}'.format(files))
    return files


def copyStartingFField(inFFstr, options):
    # these few line are duplicated; 3 times!!! Too much
    path = handleRelativeAbsolutePath(options.outputPath)
    goToPath(path)
    makeUpdateFile(path, 'ffield', inFFstr)
    return 


def printRangesToFiles(strMinMax, options):
    path = handleRelativeAbsolutePath(options.outputPath)
    goToPath(path)
    minStr = strMinMax[0]
    maxStr = strMinMax[1]
    generatedFiles = {}

    if options.mcffInput:
        makeUpdateFile(path, 'ffield')
        minF = makeUpdateFile(path, 'ffield_min', minStr)
        maxF = makeUpdateFile(path, 'ffield_max', maxStr)
        boolF = makeUpdateFile(path, 'ffield_bool')

        generatedFiles['min'] = minF
        generatedFiles['max'] = maxF
        generatedFiles['bool'] = boolF
    return generatedFiles


def printBoolToFile(boolStr, options):
    generatedFiles = {}
    path = handleRelativeAbsolutePath(options.outputPath)
    goToPath(path)

    if options.mcffInput:
        boolF = makeUpdateFile(path, 'ffield_bool', boolStr)
        generatedFiles['bool'] = boolF
    return 


def filesFromPath(path, files):
    p = handleRelativeAbsolutePath(path) # Absolute path!!! <---- call it here or inside getFiles??? Think!!!
    # by now we are sure that only existig paths are processed / recived; 
    # Everything might break, when path is wrong? Shall I pass exceptions ?
    if os.path.isfile(p):
        files.append(p)
    else:
        files.extend(getFiles(p))
    return files


def extractFilesfromArg(arg): #TODO: return list or a set? No duplications in SET!
    logging.info("Start extracting files.")
    logging.debug("arg = " + '{}'.format(arg))
 
    files = []
    for i in arg:
        logging.debug("i = " + '{}'.format(i))
        
        if isinstance(i, list):
            for item in i:
                files = filesFromPath(item, files)
            #print('files:', files)

        else:
            files = filesFromPath(i, files)
        logging.debug('{} {}'.format('files:', files))
    return files


def setYamlKeys(options, yamlObj, cathegory):
    logging.info('{:{align}{width}} {} {}'.format('Setting YAML input', cathegory, 'keys to the matching cmd input options:', align='^', width='100'))

    cathegoryObj = yamlObj[cathegory]
    cathegoryKeys = cathegoryObj.keys()
    logging.debug('{:>20} {} {}'.format("YAML", cathegory , "keys:", cathegoryKeys))

    optionsKeys = options.__dict__.keys()
    logging.debug('{:>20} {}'.format("options keys: " , optionsKeys))

    resKey = [i for i in cathegoryKeys for j in optionsKeys if i == j]
    logging.info('{:>20} {}'.format('Keys, to be set from yaml:', resKey))
    #If the key is present, than options[key] is set to this value, or set to True,
    #[keep in mind that key could be a bit different from 'destination' <- where everything is set to]
    for key in resKey:
        if cathegoryObj[key]: # If it's too complictaed - rewrite!
            if cathegory == 'input':
                options.__dict__[key] = [cathegoryObj[key]] # Make a list
            else:
                options.__dict__[key] = cathegoryObj[key] # Make a list
        elif cathegory == 'actions':
            options.__dict__[key] = True

        logging.debug('{} {} {} {}'.format('key =', key, '=', options.__dict__[key]))
    return options


def extractYamlInput(options):
    #input: path to yaml;
    #TODO: extract list of settings to be performed and set them to options;
    # Further on - process it to Task manager / engine;

    if (options.inputYaml):
        logging.debug("inputYamlOptions = " + '{}'.format(options.inputYaml))
        yamlPath = handleRelativeAbsolutePath(options.inputYaml)
        logging.debug("yamlPath = " + '{}'.format(yamlPath))
        obj = extractYamlDict(yamlPath)

        #__________KEYS:___________
        if "KEY" in obj.keys():
            options.keys = obj["KEY"] # this can be done with / without keys;
            logging.debug("Extracted KEY(s) from YAML: " + '{}'.format(options.keys))

        options = setYamlKeys(options, obj, 'input')
        if 'actions' in obj.keys():
            options = setYamlKeys(options, obj, 'actions')

    return options


def extractYamlDict(path):
    # This should be an object with 'KEY' dictionaries.
    logging.info('Extracting yaml dictionaries')
    stream = open(path, 'r')
    obj = yaml.load(stream)
    return obj


def convertQuartileFlag(flag): # move to input_output ? 
    return {
        'quartiles': 1,
        'quartiles/2': 0.5,
    }.get(flag, False) #default value;


def setLogger(options):
    logLevel = options.logLevel
    file = path + 'input_output.log'
    logging.basicConfig(format= '%(levelname)s:%(message)s', filename='input_output.log',level=logLevel) # Move creation of this file into ''
    logging.basicConfig(filename='input_output.log',level=logLevel) # Move creation of this file into ''


def parse():
    logging.info("Parsing input FF-Tool arguments.")
    parser = argparse.ArgumentParser(description='FF-Tool arguments:')

    ############## YAML-based input ##############
    parser.add_argument('--inputYaml', '--yaml', '-y', dest='inputYaml', default='', help='Path(s)[relative/absolute/from DBdir] to input yaml file(s)/dir(s), to be processed.') #All of the setting could be set through Yaml[to be Handled]

    ############## cmd - based input #############
    #__________input / output files flags________#
    parser.add_argument('--forceField', '--inputFF', '--ff', '-f', action='append', dest='inputFF',
     help='Path(s)[relative/absolute/from DBdir] to input force field file(s)/dir(s), to be processed.')
    parser.add_argument('--inputForDB', '--DBinput', '--dB', '-i', action='append', dest='DBinput', default=[], help='Path(s)[relative/absolute/from DBdir] to file(s)/dir(s) with force field file(s), to form a DataBase.')
    parser.add_argument('--keyPath', '--key', '-k', action='append', dest='inputKeys', default=[], help='Key(s)[relative/absolute/from DBdir] to YAML file(s)/dir(s) with key(s) to be processed.')
    parser.add_argument('--outputPath', '-out', '-u', dest='outputPath', default='', help='Path[relative/absolute/from DBdir] to the dir, where output will be generated.')# Default: cwd!
    parser.add_argument('--params', '-p', dest='params', type=str,
     help='Path to the params file.')
    
    #_________These few keys are only needed to normalise data/matrix; [statistical analysis]:
    parser.add_argument('--inMin', action='store', dest='inMin', default='', help='Input min file; xneeded to normalise data.')
    parser.add_argument('--inMax', action='append', dest='inMax', default='', help='Input max file; needed to normalise data.')


    #__________action / analysis flags___________#
    parser.add_argument('--ranges', '-r', choices=['minmax', 'quartiles', 'quartiles/2','M', 'Q'], dest='ranges', type=str, default='minmax',help='Choose which ranges for key(s)/file(s) to generate from DB: minmax / quartiles. By default: minmax.')
    parser.add_argument('--check', '--ch', choices=['Eq13', 'keyPresence'], dest='check', type=str, help='Choose what to check for input file(s) [inputFF].')
    parser.add_argument('--compare', '--co', choices=['keys', 'files', 'k', 'f'], dest='compare',help='Specify what to compare: keys[inputKeys] / files[inputFF].')
    parser.add_argument('--detect', '-d', action='store_true', help='Flag to detect: {branch, vdw type, chargeModel}, for an input file(s)[inputFF].')
    parser.add_argument('--ffInfo', '--info', action='store_true', help='Flag to detect and print ff info: {branch, vdw type, chargeModel}, for an input file(s)[inputFF].')
    #changing the concept of filter a bit:
    parser.add_argument('--filter', '--fl', '-F', action='append', dest='filter', default=[], help='List of rules, according to which DB should be filtered.')
    #parser.add_argument('--filter', '--fl', '-F', action='store_true', help='Flag to filter DB according to the keys present in the input: {branch, vdW type, chargeModel}')
    parser.add_argument('--mcffInput', '--mcff', action='store_true', help='Flag to generate MCFF optimiser input files (ffield, ffiled_min, ffiled_max, ffileld_bool) at the outputPath, based on the input ff, DB, key.')
    parser.add_argument('--randGuess', '--rand', action='store_true', help='Flag to generate random force field within the ranges from DataBase.')
    parser.add_argument('--bool', '--boo', action='store_true',  help='Flag to generate a bool file(ffield_bool) with parameters to be optimised, based on the input key. By default(keys are absent): all of the parameters.')
    parser.add_argument('--getKey', '-g', action='store_true', help='Flag to get value of the key(s) from the input force field file(s) [inputFF].')
    parser.add_argument('--nparr', '--np', choices=['keys', 'k'], dest='nparr', help='Generate np.arrays for the inputKeys in the files from DataBase[DBinput].')

    #__________args for filter & detect[should be empty; currently it's '?']:
    parser.add_argument('--branch' , '-b', choices=['water', 'combustion', 'independent', 'w', 'c', '?'], dest='branch', type=str, help='Specify branch.')
    parser.add_argument('--vanDerWaals', '--vdw', '-w', choices=['iw+sh', 'iw', 'sh', 'no', 'InnerWall+Shileding', 'InnerWall+NoShielding', 'NoInnerWall+Shielding', '?'], type=str, help='Specify Van der Waals interaction type.')
    parser.add_argument('--chargeMethod', '--charge', '-q', choices=['EEM', 'ACKS2', '?'], type=str, default='EEM', help='Specify charge model. By default: EEM.')

    #__________Object flags______________________#
    parser.add_argument('--object', '-o', choices=['key', 'file', 'dataBase', 'k', 'f', 'd'], type=str, help='Object for performing an operation(s): {key(s)[keyPath], file(s)[inputFF], DB[DBinput]}.') #Ideally it should be clear from the flags combination.

    parser.add_argument('--logLevel', '--log', choices=['ERROR', 'WARNING', 'INFO', 'DEBUG'], type=str, dest='logLevel', default='INFO', help='Set log level.') #TODO: Think over; + handle int as an input value;

    options = parser.parse_args()
    return options

def updateArgs(options):
    logging.info('Updating input arguments, dependent on the path:')
    ##### ff: #####
    if (options.inputFF):
        options.inputFF = extractFilesfromArg(options.inputFF) # List of files to be processed further;
        logging.debug("Force field file(s):[inputFF] = " + '{}'.format(options.inputFF))
    ##############

    ##### DB: #####
    if (options.DBinput):
        options.DBinput = extractFilesfromArg(options.DBinput) # Basically, updating options values;
        logging.debug("DB input file(s):[DBinput] = " + '{}'.format(options.DBinput))
    ##############

    ##### Normalisation part]:
    if (options.inMin and options.inMax):
        options.inMin = extractFilesfromArg(options.inMin)
        options.inMax = extractFilesfromArg(options.inMax)
        logging.debug("Min/max input file(s) for Normalization:[inMin, inMax] = " + '{} {}'.format(options.inMin, options.inMax))
    ##############

    ##### KEY: ####
    #keys = extractYamls()
    #1. Check if they are input from console;
    #2. If not - they are files, I'll need to extract
    if(options.inputKeys):
        keysFiles = extractFilesfromArg(options.inputKeys) #Gonna be YAMLs;
        logging.debug("KEY(s) file(s) = " + '{}'.format(keysFiles))
        for file in keysFiles:
            print (">> KEY(s):" , extractYamlDict(file)["KEY"]) # this dictionary will be the KEY!!!
            logging.debug(" KEY(s): " + '{}'.format(extractYamlDict(file)["KEY"]))
    ###############
    return options

def getInputArgs():
    options = parse()
    options = extractYamlInput(options)
    options = updateArgs(options)
    return options
    